{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/onions/miniforge3/lib/python3.9/site-packages (2.0.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/onions/miniforge3/lib/python3.9/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/onions/miniforge3/lib/python3.9/site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/onions/miniforge3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/onions/miniforge3/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/onions/miniforge3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>建言类型</th>\n",
       "      <th>问题</th>\n",
       "      <th>改进意见</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>用户隐私数据保护措施不完善</td>\n",
       "      <td>加强数据加密和权限申请，确保用户个人信息安全。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>存在安全漏洞容易受到黑客攻击</td>\n",
       "      <td>加强网络安全防护，定期进行漏洞修复和安全测试，确保用户数据的安全性。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>系统登录认证方式薄弱，易受到非法访问</td>\n",
       "      <td>改进系统登录认证机制，增加多重身份验证，提高账号安全性。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>缺乏日志监控和异常检测机制</td>\n",
       "      <td>建立日志监控和异常检测系统，及时发现和应对安全威胁。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>内部员工权限管理混乱，存在安全隐患</td>\n",
       "      <td>加强员工权限管理，实行权限分级制度，防止数据泄露。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   建言类型                  问题                                改进意见\n",
       "0  安全隐患       用户隐私数据保护措施不完善             加强数据加密和权限申请，确保用户个人信息安全。\n",
       "1  安全隐患      存在安全漏洞容易受到黑客攻击  加强网络安全防护，定期进行漏洞修复和安全测试，确保用户数据的安全性。\n",
       "2  安全隐患  系统登录认证方式薄弱，易受到非法访问        改进系统登录认证机制，增加多重身份验证，提高账号安全性。\n",
       "3  安全隐患       缺乏日志监控和异常检测机制          建立日志监控和异常检测系统，及时发现和应对安全威胁。\n",
       "4  安全隐患   内部员工权限管理混乱，存在安全隐患           加强员工权限管理，实行权限分级制度，防止数据泄露。"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv', encoding='gbk')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>suggestions</th>\n",
       "      <th>text1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>用户隐私数据保护措施不完善</td>\n",
       "      <td>加强数据加密和权限申请，确保用户个人信息安全。</td>\n",
       "      <td>用户隐私数据保护措施不完善,加强数据加密和权限申请，确保用户个人信息安全。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>存在安全漏洞容易受到黑客攻击</td>\n",
       "      <td>加强网络安全防护，定期进行漏洞修复和安全测试，确保用户数据的安全性。</td>\n",
       "      <td>存在安全漏洞容易受到黑客攻击,加强网络安全防护，定期进行漏洞修复和安全测试，确保用户数据的安全性。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>系统登录认证方式薄弱，易受到非法访问</td>\n",
       "      <td>改进系统登录认证机制，增加多重身份验证，提高账号安全性。</td>\n",
       "      <td>系统登录认证方式薄弱，易受到非法访问,改进系统登录认证机制，增加多重身份验证，提高账号安全性。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>缺乏日志监控和异常检测机制</td>\n",
       "      <td>建立日志监控和异常检测系统，及时发现和应对安全威胁。</td>\n",
       "      <td>缺乏日志监控和异常检测机制,建立日志监控和异常检测系统，及时发现和应对安全威胁。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>内部员工权限管理混乱，存在安全隐患</td>\n",
       "      <td>加强员工权限管理，实行权限分级制度，防止数据泄露。</td>\n",
       "      <td>内部员工权限管理混乱，存在安全隐患,加强员工权限管理，实行权限分级制度，防止数据泄露。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                text                         suggestions  \\\n",
       "0  安全隐患       用户隐私数据保护措施不完善             加强数据加密和权限申请，确保用户个人信息安全。   \n",
       "1  安全隐患      存在安全漏洞容易受到黑客攻击  加强网络安全防护，定期进行漏洞修复和安全测试，确保用户数据的安全性。   \n",
       "2  安全隐患  系统登录认证方式薄弱，易受到非法访问        改进系统登录认证机制，增加多重身份验证，提高账号安全性。   \n",
       "3  安全隐患       缺乏日志监控和异常检测机制          建立日志监控和异常检测系统，及时发现和应对安全威胁。   \n",
       "4  安全隐患   内部员工权限管理混乱，存在安全隐患           加强员工权限管理，实行权限分级制度，防止数据泄露。   \n",
       "\n",
       "                                               text1  \n",
       "0              用户隐私数据保护措施不完善,加强数据加密和权限申请，确保用户个人信息安全。  \n",
       "1  存在安全漏洞容易受到黑客攻击,加强网络安全防护，定期进行漏洞修复和安全测试，确保用户数据的安全性。  \n",
       "2    系统登录认证方式薄弱，易受到非法访问,改进系统登录认证机制，增加多重身份验证，提高账号安全性。  \n",
       "3           缺乏日志监控和异常检测机制,建立日志监控和异常检测系统，及时发现和应对安全威胁。  \n",
       "4        内部员工权限管理混乱，存在安全隐患,加强员工权限管理，实行权限分级制度，防止数据泄露。  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'建言类型':'label', '问题':'text', '改进意见':'suggestions'}, inplace=True)\n",
    "# df.head()\n",
    "df['label'] = df['label'].apply(lambda x: str(x))\n",
    "df['text'] = df['text'].apply(lambda x: str(x))\n",
    "df['suggestions'] = df['suggestions'].apply(lambda x: str(x))\n",
    "df['text1'] = df['text'] + ',' + df['suggestions']\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>用户隐私数据保护措施不完善,加强数据加密和权限申请，确保用户个人信息安全。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>存在安全漏洞容易受到黑客攻击,加强网络安全防护，定期进行漏洞修复和安全测试，确保用户数据的安全性。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>系统登录认证方式薄弱，易受到非法访问,改进系统登录认证机制，增加多重身份验证，提高账号安全性。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>缺乏日志监控和异常检测机制,建立日志监控和异常检测系统，及时发现和应对安全威胁。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>安全隐患</td>\n",
       "      <td>内部员工权限管理混乱，存在安全隐患,加强员工权限管理，实行权限分级制度，防止数据泄露。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0  安全隐患              用户隐私数据保护措施不完善,加强数据加密和权限申请，确保用户个人信息安全。\n",
       "1  安全隐患  存在安全漏洞容易受到黑客攻击,加强网络安全防护，定期进行漏洞修复和安全测试，确保用户数据的安全性。\n",
       "2  安全隐患    系统登录认证方式薄弱，易受到非法访问,改进系统登录认证机制，增加多重身份验证，提高账号安全性。\n",
       "3  安全隐患           缺乏日志监控和异常检测机制,建立日志监控和异常检测系统，及时发现和应对安全威胁。\n",
       "4  安全隐患        内部员工权限管理混乱，存在安全隐患,加强员工权限管理，实行权限分级制度，防止数据泄露。"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df['text1']\n",
    "df.drop(labels=['text'], axis=1, inplace=True)\n",
    "df.drop(labels=['suggestions'], axis=1, inplace=True)\n",
    "df.rename(columns={'text1':'text'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将标签从汉字准换为数字？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pip install scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "label = df.label\n",
    "df.drop(columns='label', inplace=True)\n",
    "\n",
    "df_train, df_test, y_train, y_test = train_test_split(df, label, test_size = 0.2, stratify = label, random_state = 42)\n",
    "df_train['label'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>客户服务质量不稳定，需提升服务一致性,制定统一的客户服务标准，确保服务质量一致性和稳定性。</td>\n",
       "      <td>客户服务</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>客户服务流程复杂，需简化服务流程,简化客户服务流程，提高服务效率，节省客户时间。</td>\n",
       "      <td>客户服务</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>网站内容更新不及时，影响用户粘性,定期更新网站内容，提供有价值的信息，增加用户粘性。</td>\n",
       "      <td>网络运营</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>存在安全漏洞容易受到黑客攻击,加强网络安全防护，定期进行漏洞修复和安全测试，确保用户数据的安全性。</td>\n",
       "      <td>安全隐患</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>客户投诉处理流程繁琐，影响用户满意度,简化投诉处理流程，提高问题解决效率，增强用户体验。</td>\n",
       "      <td>客户服务</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text label\n",
       "76       客户服务质量不稳定，需提升服务一致性,制定统一的客户服务标准，确保服务质量一致性和稳定性。  客户服务\n",
       "65            客户服务流程复杂，需简化服务流程,简化客户服务流程，提高服务效率，节省客户时间。  客户服务\n",
       "161         网站内容更新不及时，影响用户粘性,定期更新网站内容，提供有价值的信息，增加用户粘性。  网络运营\n",
       "192  存在安全漏洞容易受到黑客攻击,加强网络安全防护，定期进行漏洞修复和安全测试，确保用户数据的安全性。  安全隐患\n",
       "54        客户投诉处理流程繁琐，影响用户满意度,简化投诉处理流程，提高问题解决效率，增强用户体验。  客户服务"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分训练集和验证集\n",
    "label = df_train.label\n",
    "df_train.drop(columns='label', inplace=True)\n",
    "\n",
    "df_train, df_val, y_train, y_val = train_test_split(\n",
    "    df_train, label, test_size=0.05, stratify=label, random_state=42\n",
    ")\n",
    "df_train['label'] = y_train\n",
    "df_val['label'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更改为transformers数据集\n",
    "from datasets import Dataset, DatasetDict\n",
    "data = DatasetDict()\n",
    "data['train'] = Dataset.from_pandas(df_train)\n",
    "data['validation'] = Dataset.from_pandas(df_val)\n",
    "data['test'] = Dataset.from_pandas(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: accelerate in /Users/onions/miniforge3/envs/heatmap/lib/python3.8/site-packages (0.21.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/onions/miniforge3/envs/heatmap/lib/python3.8/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in /Users/onions/miniforge3/envs/heatmap/lib/python3.8/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/onions/miniforge3/envs/heatmap/lib/python3.8/site-packages (from accelerate) (1.23.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/onions/miniforge3/envs/heatmap/lib/python3.8/site-packages (from accelerate) (2.0.0.dev20221212)\n",
      "Requirement already satisfied: pyyaml in /Users/onions/miniforge3/envs/heatmap/lib/python3.8/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: typing_extensions in /Users/onions/miniforge3/envs/heatmap/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: sympy in /Users/onions/miniforge3/envs/heatmap/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/onions/miniforge3/envs/heatmap/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.8.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/onions/miniforge3/envs/heatmap/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install accelerate -U\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 11.2kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 624/624 [00:00<00:00, 324kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 110k/110k [00:00<00:00, 814kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 269k/269k [00:00<00:00, 476kB/s]\n",
      "Map: 100%|██████████| 178/178 [00:00<00:00, 19234.47 examples/s]\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 3164.32 examples/s]\n",
      "Map: 100%|██████████| 47/47 [00:00<00:00, 10609.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 对文本进行编码\n",
    "from transformers import AutoTokenizer\n",
    "model_pretrained = 'bert-base-chinese'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_pretrained)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "encoded = data.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "zsh:1: no matches found: transformers[torch]\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预训练模型微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onions/miniforge3/envs/heatmap/lib/python3.8/site-packages/safetensors/torch.py:17: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor._storage() instead of tensor.storage()\n",
      "  return tensor.storage().data_ptr()\n",
      "/Users/onions/miniforge3/envs/heatmap/lib/python3.8/site-packages/safetensors/torch.py:29: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor._storage() instead of tensor.storage()\n",
      "  return tensor.storage().size() * _SIZE[tensor.dtype]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m logging_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[1;32m     16\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_pretrained\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-finetuned-suggestions\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 18\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43merror\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 训练模型和评估\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n",
      "File \u001b[0;32m<string>:112\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, xpu_backend)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/heatmap/lib/python3.8/site-packages/transformers/training_args.py:1372\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(version\u001b[38;5;241m.\u001b[39mparse(torch\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mbase_version) \u001b[38;5;241m==\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16:\n\u001b[1;32m   1367\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1371\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m-> 1372\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (get_xla_device_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_full_eval)\n\u001b[1;32m   1375\u001b[0m ):\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--fp16_full_eval`) can only be used on CUDA devices.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1379\u001b[0m     )\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1388\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_full_eval)\n\u001b[1;32m   1389\u001b[0m ):\n",
      "File \u001b[0;32m~/miniforge3/envs/heatmap/lib/python3.8/site-packages/transformers/training_args.py:1795\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1794\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 1795\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/heatmap/lib/python3.8/site-packages/transformers/utils/generic.py:54\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     52\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[0;32m~/miniforge3/envs/heatmap/lib/python3.8/site-packages/transformers/training_args.py:1716\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   1715\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available(min_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.20.1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1716\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   1717\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1718\u001b[0m         )\n\u001b[1;32m   1719\u001b[0m     AcceleratorState\u001b[38;5;241m.\u001b[39m_reset_state(reset_partial_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('mps' if torch.has_mps else 'cpu')\n",
    "\n",
    "#实例化模型\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_pretrained, num_labels=4\n",
    ").to(device)\n",
    "\n",
    "# 设置训练参数\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "batch_size = 4\n",
    "logging_steps = len(encoded['train']) // batch_size\n",
    "model_name = f'{model_pretrained}-finetuned-suggestions'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    report_to='none',\n",
    "    output_dir=model_name,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    log_level='error',\n",
    ")\n",
    "\n",
    "# 训练模型和评估\n",
    "from transformers import Trainer\n",
    "from sklearn import accuracy_score, f1_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.prediction.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy':'acc', 'f1':f1}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=encoded['train'],\n",
    "    eval_dataset=encoded['validation'],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
